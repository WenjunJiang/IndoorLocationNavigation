{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.layers import WeightNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 10\n",
    "\n",
    "SEED = 2021\n",
    "\n",
    "NUM_FEATS = 20 # number of features that we use. there are 100 feats but we don't need to use all of them\n",
    "\n",
    "base_path = '/Users/anooshhari/Documents/Anoosh/Masters/Spring 21/Classes/6100 - BigData Analytics for C/Indoor Location Navigation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "        intra_op_parallelism_threads=1,\n",
    "        inter_op_parallelism_threads=1\n",
    "    )\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    \n",
    "def comp_metric(xhat, yhat, fhat, x, y, f):\n",
    "    intermediate = np.sqrt(np.power(xhat-x, 2) + np.power(yhat-y, 2)) + 15 * np.abs(fhat-f)\n",
    "    return intermediate.sum()/xhat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dir = f\"{base_path}/input/indoorunifiedwifids\"\n",
    "train_files = sorted(glob.glob(os.path.join(feature_dir, '*_train.csv')))\n",
    "test_files = sorted(glob.glob(os.path.join(feature_dir, '*_test.csv')))\n",
    "subm = pd.read_csv(f'{base_path}/input/indoor-location-navigation/sample_submission.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{feature_dir}/train_all.pkl', 'rb') as f:\n",
    "  data = pickle.load(f)\n",
    "\n",
    "with open(f'{feature_dir}/test_all.pkl', 'rb') as f:\n",
    "  test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSSID_FEATS = [f'bssid_{i}' for i in range(NUM_FEATS)]\n",
    "RSSI_FEATS  = [f'rssi_{i}' for i in range(NUM_FEATS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BSSID TYPES: 61206\n",
      "BSSID TYPES: 33042\n"
     ]
    }
   ],
   "source": [
    "wifi_bssids = []\n",
    "for i in range(100):\n",
    "    wifi_bssids.extend(data.iloc[:,i].values.tolist())\n",
    "wifi_bssids = list(set(wifi_bssids))\n",
    "\n",
    "wifi_bssids_size = len(wifi_bssids)\n",
    "print(f'BSSID TYPES: {wifi_bssids_size}')\n",
    "\n",
    "wifi_bssids_test = []\n",
    "for i in range(100):\n",
    "    wifi_bssids_test.extend(test_data.iloc[:,i].values.tolist())\n",
    "wifi_bssids_test = list(set(wifi_bssids_test))\n",
    "\n",
    "wifi_bssids_size = len(wifi_bssids_test)\n",
    "print(f'BSSID TYPES: {wifi_bssids_size}')\n",
    "\n",
    "wifi_bssids.extend(wifi_bssids_test)\n",
    "wifi_bssids_size = len(wifi_bssids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(wifi_bssids)\n",
    "le_site = LabelEncoder()\n",
    "le_site.fit(data['site_id'])\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(data.loc[:,RSSI_FEATS+['floor']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:,RSSI_FEATS+['floor']] = ss.transform(data.loc[:,RSSI_FEATS+['floor']])\n",
    "for i in BSSID_FEATS:\n",
    "    data.loc[:,i] = le.transform(data.loc[:,i])\n",
    "    data.loc[:,i] = data.loc[:,i] + 1\n",
    "    \n",
    "data.loc[:, 'site_id'] = le_site.transform(data.loc[:, 'site_id'])\n",
    "\n",
    "data.loc[:,RSSI_FEATS+['floor']] = ss.transform(data.loc[:,RSSI_FEATS+['floor']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_output = pd.read_csv('./input/lgbm-output/submission.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['floor'] = lgbm_output['floor'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.loc[:,RSSI_FEATS+['floor']] = ss.transform(test_data.loc[:,RSSI_FEATS+['floor']])\n",
    "for i in BSSID_FEATS:\n",
    "    test_data.loc[:,i] = le.transform(test_data.loc[:,i])\n",
    "    test_data.loc[:,i] = test_data.loc[:,i] + 1\n",
    "    \n",
    "test_data.loc[:, 'site_id'] = le_site.transform(test_data.loc[:, 'site_id'])\n",
    "\n",
    "test_data.loc[:,RSSI_FEATS+['floor']] = ss.transform(test_data.loc[:,RSSI_FEATS+['floor']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_count = len(data['site_id'].unique())\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_data):\n",
    "\n",
    "    # bssid feats\n",
    "    input_dim = input_data[0].shape[1]\n",
    "\n",
    "    input_embd_layer = L.Input(shape=(input_dim,))\n",
    "    x1 = L.Embedding(wifi_bssids_size, 64)(input_embd_layer)\n",
    "    x1 = L.Flatten()(x1)\n",
    "\n",
    "    # rssi feats\n",
    "    input_dim = input_data[1].shape[1]\n",
    "\n",
    "    input_layer = L.Input(input_dim, )\n",
    "    x2 = L.BatchNormalization()(input_layer)\n",
    "    x2 = L.Dense(NUM_FEATS * 64, activation='relu')(x2)\n",
    "\n",
    "    # site\n",
    "    input_site_layer = L.Input(shape=(1,))\n",
    "    x3 = L.Embedding(site_count, 1)(input_site_layer)\n",
    "    x3 = L.Flatten()(x3)\n",
    "\n",
    "    x = L.Concatenate(axis=1)([x1, x3, x2])\n",
    "\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Dropout(0.3)(x)\n",
    "    x = L.Dense(256, activation='relu')(x)\n",
    "\n",
    "    x = L.Reshape((1, -1))(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    #x = L.LSTM(128, dropout=0.3, recurrent_dropout=0.3, return_sequences=True, activation='relu')(x)\n",
    "    x = L.LSTM(256, dropout=0.3, recurrent_dropout=0.3, return_sequences=True, activation='relu')(x)\n",
    "    x = L.LSTM(16, dropout=0.1, return_sequences=False, activation='relu')(x)\n",
    "\n",
    "    \n",
    "    output_layer_1 = L.Dense(2, name='xy')(x)\n",
    "    #output_layer_2 = L.Dense(1, activation='softmax', name='floor')(x)\n",
    "\n",
    "    model = M.Model([input_embd_layer, input_layer, input_site_layer], \n",
    "                    [output_layer_1])\n",
    "\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.001),\n",
    "                  loss='mse', metrics=['mse'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anooshhari/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1815/1815 [==============================] - 130s 69ms/step - loss: 2415.1573 - mse: 2415.1573 - val_loss: 83.4723 - val_mse: 83.4723\n",
      "Epoch 2/1000\n",
      "1815/1815 [==============================] - 117s 65ms/step - loss: 184.8052 - mse: 184.8052 - val_loss: 64.6820 - val_mse: 64.6820\n",
      "Epoch 3/1000\n",
      "1815/1815 [==============================] - 113s 62ms/step - loss: 149.3449 - mse: 149.3449 - val_loss: 53.7179 - val_mse: 53.7179\n",
      "Epoch 4/1000\n",
      "1815/1815 [==============================] - 116s 64ms/step - loss: 126.1830 - mse: 126.1830 - val_loss: 46.2580 - val_mse: 46.2580\n",
      "Epoch 5/1000\n",
      "1815/1815 [==============================] - 118s 65ms/step - loss: 111.4236 - mse: 111.4236 - val_loss: 41.2625 - val_mse: 41.2625\n",
      "Epoch 6/1000\n",
      "1815/1815 [==============================] - 120s 66ms/step - loss: 96.5962 - mse: 96.5962 - val_loss: 39.1685 - val_mse: 39.1685\n",
      "Epoch 7/1000\n",
      "1815/1815 [==============================] - 128s 70ms/step - loss: 85.0360 - mse: 85.0360 - val_loss: 37.2828 - val_mse: 37.2828\n",
      "Epoch 8/1000\n",
      "1815/1815 [==============================] - 129s 71ms/step - loss: 73.4942 - mse: 73.4942 - val_loss: 34.5923 - val_mse: 34.5923\n",
      "Epoch 9/1000\n",
      "1815/1815 [==============================] - 132s 73ms/step - loss: 64.8793 - mse: 64.8793 - val_loss: 32.3729 - val_mse: 32.3729\n",
      "Epoch 10/1000\n",
      "1815/1815 [==============================] - 128s 71ms/step - loss: 57.0931 - mse: 57.0931 - val_loss: 35.3023 - val_mse: 35.3023\n",
      "Epoch 11/1000\n",
      "1815/1815 [==============================] - 128s 71ms/step - loss: 51.9365 - mse: 51.9365 - val_loss: 33.0128 - val_mse: 33.0128\n",
      "Epoch 12/1000\n",
      "1815/1815 [==============================] - 138s 76ms/step - loss: 47.8030 - mse: 47.8030 - val_loss: 32.9251 - val_mse: 32.9251\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 13/1000\n",
      "1815/1815 [==============================] - 137s 76ms/step - loss: 40.6386 - mse: 40.6386 - val_loss: 25.9560 - val_mse: 25.9560\n",
      "Epoch 14/1000\n",
      "1815/1815 [==============================] - 143s 79ms/step - loss: 38.4783 - mse: 38.4783 - val_loss: 26.6171 - val_mse: 26.6171\n",
      "Epoch 15/1000\n",
      "1815/1815 [==============================] - 136s 75ms/step - loss: 37.4585 - mse: 37.4585 - val_loss: 25.8978 - val_mse: 25.8978\n",
      "Epoch 16/1000\n",
      "1815/1815 [==============================] - 139s 76ms/step - loss: 36.7602 - mse: 36.7602 - val_loss: 24.8618 - val_mse: 24.8618\n",
      "Epoch 17/1000\n",
      "1815/1815 [==============================] - 126s 69ms/step - loss: 36.1055 - mse: 36.1055 - val_loss: 25.6303 - val_mse: 25.6303\n",
      "Epoch 18/1000\n",
      "1815/1815 [==============================] - 122s 67ms/step - loss: 35.6410 - mse: 35.6410 - val_loss: 25.6374 - val_mse: 25.6374\n",
      "Epoch 19/1000\n",
      "1815/1815 [==============================] - 119s 66ms/step - loss: 35.3767 - mse: 35.3767 - val_loss: 24.8013 - val_mse: 24.8013\n",
      "Epoch 20/1000\n",
      "1815/1815 [==============================] - 123s 68ms/step - loss: 34.8050 - mse: 34.8050 - val_loss: 25.0053 - val_mse: 25.0053\n",
      "Epoch 21/1000\n",
      "1815/1815 [==============================] - 118s 65ms/step - loss: 34.5659 - mse: 34.5659 - val_loss: 25.4039 - val_mse: 25.4039\n",
      "Epoch 22/1000\n",
      "1815/1815 [==============================] - 119s 66ms/step - loss: 34.1478 - mse: 34.1478 - val_loss: 25.0575 - val_mse: 25.0575\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 23/1000\n",
      "1815/1815 [==============================] - 118s 65ms/step - loss: 33.5548 - mse: 33.5548 - val_loss: 25.0679 - val_mse: 25.0679\n",
      "Epoch 24/1000\n",
      "1815/1815 [==============================] - 2589s 1s/step - loss: 33.3150 - mse: 33.3150 - val_loss: 24.3269 - val_mse: 24.3269\n",
      "Epoch 25/1000\n",
      "1815/1815 [==============================] - 127s 70ms/step - loss: 33.1215 - mse: 33.1215 - val_loss: 25.2011 - val_mse: 25.2011\n",
      "Epoch 26/1000\n",
      "1815/1815 [==============================] - 118s 65ms/step - loss: 32.8066 - mse: 32.8066 - val_loss: 25.1747 - val_mse: 25.1747\n",
      "Epoch 27/1000\n",
      "1815/1815 [==============================] - 121s 67ms/step - loss: 33.0027 - mse: 33.0027 - val_loss: 25.4880 - val_mse: 25.4880\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 28/1000\n",
      "1815/1815 [==============================] - 123s 68ms/step - loss: 32.6734 - mse: 32.6734 - val_loss: 25.1735 - val_mse: 25.1735\n",
      "Epoch 29/1000\n",
      "1815/1815 [==============================] - 130s 72ms/step - loss: 32.8560 - mse: 32.8560 - val_loss: 25.3407 - val_mse: 25.3407\n",
      "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n",
      "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n"
     ]
    }
   ],
   "source": [
    "score_df = pd.DataFrame()\n",
    "predictions = list()\n",
    "\n",
    "preds_x, preds_y = 0, 0\n",
    "preds_f_arr = np.zeros((test_data.shape[0], N_SPLITS))\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED).split(data.loc[:, 'path'], data.loc[:, 'path'])):\n",
    "    X_train = data.loc[trn_idx, BSSID_FEATS + RSSI_FEATS + ['floor','site_id']]\n",
    "    y_trainx = data.loc[trn_idx, 'x']\n",
    "    y_trainy = data.loc[trn_idx, 'y']\n",
    "    y_trainf = data.loc[trn_idx, 'floor']\n",
    "\n",
    "    tmp = pd.concat([y_trainx, y_trainy], axis=1)\n",
    "    #y_train = [tmp, y_trainf]\n",
    "    y_train = tmp\n",
    "\n",
    "    X_valid = data.loc[val_idx, BSSID_FEATS + RSSI_FEATS + ['floor','site_id']]\n",
    "    y_validx = data.loc[val_idx, 'x']\n",
    "    y_validy = data.loc[val_idx, 'y']\n",
    "    y_validf = data.loc[val_idx, 'floor']\n",
    "\n",
    "    tmp = pd.concat([y_validx, y_validy], axis=1)\n",
    "    #y_valid = [tmp, y_validf]\n",
    "    y_valid = tmp\n",
    "\n",
    "    model = create_model([X_train.loc[:,BSSID_FEATS], X_train.loc[:,RSSI_FEATS+['floor']], X_train.loc[:,'site_id']])\n",
    "    model.fit([X_train.loc[:,BSSID_FEATS], X_train.loc[:,RSSI_FEATS+['floor']], X_train.loc[:,'site_id']], y_train, \n",
    "                validation_data=([X_valid.loc[:,BSSID_FEATS], X_valid.loc[:,RSSI_FEATS+['floor']], X_valid.loc[:,'site_id']], y_valid), \n",
    "                batch_size=128, epochs=1000,\n",
    "                callbacks=[\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_delta=1e-4, mode='min')\n",
    "                , ModelCheckpoint(f'{base_path}/RNN_{SEED}_{fold}.hdf5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min')\n",
    "                , EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, mode='min', baseline=None, restore_best_weights=True)\n",
    "            ])\n",
    "\n",
    "    model.load_weights(f'{base_path}/RNN_{SEED}_{fold}.hdf5')\n",
    "    #val_pred = model.predict([X_valid.loc[:,BSSID_FEATS], X_valid.loc[:,RSSI_FEATS], X_valid.loc[:,'site_id'], X_valid.loc[:,'floor']])\n",
    "\n",
    "    pred = model.predict([test_data.loc[:,BSSID_FEATS], test_data.loc[:,RSSI_FEATS+['floor']], test_data.loc[:,'site_id']]) # test_data.iloc[:, :-1])\n",
    "    preds_x += pred[:,0]\n",
    "    preds_y += pred[:,1]\n",
    "    #preds_f_arr[:, fold] = pred[1][:,0].astype(int)\n",
    "\n",
    "    \n",
    "\n",
    "    break # for demonstration, run just one fold as it takes much time.\n",
    "\n",
    "preds_x /= (fold + 1)\n",
    "preds_y /= (fold + 1)\n",
    "    \n",
    "print(\"*+\"*40)\n",
    "print(\"*+\"*40)\n",
    "\n",
    "#preds_f_mode = stats.mode(preds_f_arr, axis=1)\n",
    "#preds_f = preds_f_mode[0].astype(int).reshape(-1)\n",
    "preds_f = test_data['floor']\n",
    "test_preds = pd.DataFrame(np.stack((preds_f, preds_x, preds_y))).T\n",
    "test_preds.columns = subm.columns\n",
    "test_preds.index = test_data[\"site_path_timestamp\"]\n",
    "test_preds[\"floor\"] = test_preds[\"floor\"].astype(int)\n",
    "predictions.append(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = pd.concat(predictions)\n",
    "all_preds = all_preds.reindex(subm.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_output = pd.read_csv('./input/lgbm-output/submission.csv')\n",
    "\n",
    "# all_preds['floor'] = lgbm_output['floor'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
